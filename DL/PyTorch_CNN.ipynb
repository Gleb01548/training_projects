{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3.2 - сверточные нейронные сети (CNNs) в PyTorch\n",
    "\n",
    "Это упражнение мы буде выполнять в Google Colab - https://colab.research.google.com/  \n",
    "Google Colab позволяет запускать код в notebook в облаке Google, где можно воспользоваться бесплатным GPU!  \n",
    "\n",
    "Авторы курса благодарят компанию Google и надеятся, что праздник не закончится.\n",
    "\n",
    "Туториал по настройке Google Colab:  \n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d  \n",
    "(Keras инсталлировать не нужно, наш notebook сам установит PyTorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FcXBeP1O7cnY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\budni\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\budni\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\budni\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\budni\\anaconda3\\lib\\site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: requests in c:\\users\\budni\\anaconda3\\lib\\site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\budni\\anaconda3\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\budni\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\budni\\anaconda3\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\budni\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\budni\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n"
     ]
    }
   ],
   "source": [
    "# Intstall PyTorch and download data\n",
    "!pip3 install torch torchvision\n",
    "\n",
    "!wget -c http://ufldl.stanford.edu/housenumbers/train_32x32.mat http://ufldl.stanford.edu/housenumbers/test_32x32.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-afwWw-Q85vD"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNU-OD9O9ltP"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") # Let's make sure GPU is available!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAvkoRx-9FsP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# First, lets load the dataset\n",
    "data_train = dset.SVHN('data/', \n",
    "                       download = True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                          \n",
    "                       ])\n",
    "                      )\n",
    "data_test = dset.SVHN('data/', split='test', \n",
    "                      download = True,\n",
    "                      transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                           \n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "new = dset.SVHN('data/', split='test', \n",
    "                      download = True,          \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1490, 0.1529, 0.1529,  ..., 0.1608, 0.1647, 0.1529],\n",
       "         [0.1529, 0.1529, 0.1529,  ..., 0.1608, 0.1686, 0.1529],\n",
       "         [0.1490, 0.1451, 0.1529,  ..., 0.1686, 0.1686, 0.1529],\n",
       "         ...,\n",
       "         [0.2039, 0.2078, 0.2000,  ..., 0.1725, 0.1725, 0.1608],\n",
       "         [0.1961, 0.2000, 0.1922,  ..., 0.1725, 0.1765, 0.1647],\n",
       "         [0.1882, 0.1882, 0.1804,  ..., 0.1686, 0.1725, 0.1647]],\n",
       "\n",
       "        [[0.4039, 0.4078, 0.4078,  ..., 0.4000, 0.4039, 0.3804],\n",
       "         [0.4078, 0.4078, 0.4078,  ..., 0.4000, 0.3961, 0.3804],\n",
       "         [0.4118, 0.4078, 0.4157,  ..., 0.3961, 0.3922, 0.3804],\n",
       "         ...,\n",
       "         [0.4667, 0.4706, 0.4627,  ..., 0.4627, 0.4588, 0.4471],\n",
       "         [0.4588, 0.4627, 0.4549,  ..., 0.4588, 0.4549, 0.4431],\n",
       "         [0.4510, 0.4510, 0.4431,  ..., 0.4549, 0.4510, 0.4431]],\n",
       "\n",
       "        [[0.2353, 0.2392, 0.2431,  ..., 0.2392, 0.2431, 0.2235],\n",
       "         [0.2392, 0.2392, 0.2431,  ..., 0.2392, 0.2471, 0.2235],\n",
       "         [0.2431, 0.2392, 0.2471,  ..., 0.2471, 0.2510, 0.2314],\n",
       "         ...,\n",
       "         [0.3059, 0.3098, 0.3020,  ..., 0.2706, 0.2784, 0.2706],\n",
       "         [0.2980, 0.3020, 0.2941,  ..., 0.2784, 0.2824, 0.2706],\n",
       "         [0.2902, 0.2902, 0.2824,  ..., 0.2784, 0.2784, 0.2784]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = transforms.ToTensor()\n",
    "q(new[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на training и validation.\n",
    "\n",
    "На всякий случай для подробностей - https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRnr8CPg7Hli"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "data_size = data_train.data.shape[0]\n",
    "validation_split = .2\n",
    "split = int(np.floor(validation_split * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LyYvt-T67PBG"
   },
   "outputs": [],
   "source": [
    "# We'll use a special helper module to shape it into a flat tensor\n",
    "class Flattener(nn.Module):\n",
    "    def forward(self, x):\n",
    "        batch_size, *_ = x.shape\n",
    "        return x.view(batch_size, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейшую сеть с новыми слоями:  \n",
    "Convolutional - `nn.Conv2d`  \n",
    "MaxPool - `nn.MaxPool2d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w9SFVGZP7SQd"
   },
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),    \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*2*2, 10),\n",
    "          )\n",
    "\n",
    "nn_model.type(torch.cuda.FloatTensor)\n",
    "nn_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Восстановите функцию `compute_accuracy` из прошлого задания.  \n",
    "Единственное отличие в новом - она должна передать данные на GPU прежде чем прогонять через модель. Сделайте это так же, как это делает функция `train_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ek3KVQK7hJ6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.420861, Train accuracy: 0.524554, Val accuracy: 0.678111\n",
      "Average loss: 0.730125, Train accuracy: 0.777002, Val accuracy: 0.807112\n",
      "Average loss: 0.614526, Train accuracy: 0.816913, Val accuracy: 0.816600\n",
      "Average loss: 0.564348, Train accuracy: 0.833891, Val accuracy: 0.836325\n",
      "Average loss: 0.529403, Train accuracy: 0.843617, Val accuracy: 0.826974\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "          \n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes accuracy on the dataset wrapped in a loader\n",
    "    \n",
    "    Returns: accuracy as a float value between 0 and 1\n",
    "    \"\"\"\n",
    "    model.eval() # Evaluation mode\n",
    "    val_size = 0\n",
    "    good_predict = 0\n",
    "    model.eval() # Evaluation mode\n",
    "    for i_step, (X, y) in enumerate(loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        prediction = model(X)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        good_predict += torch.sum(index == y)\n",
    "        val_size += X.shape[0]\n",
    "    \n",
    "    accuracy =  float(good_predict)/val_size\n",
    "    \n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "    # TODO: Copy implementation from previous assignment\n",
    "    # Don't forget to move the data to device before running it through the model!\n",
    "    \n",
    "    raise Exception(\"Not implemented\")\n",
    "\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6a-3a1ZFGEw_"
   },
   "source": [
    "# Аугментация данных (Data augmentation)\n",
    "\n",
    "В работе с изображениями одним из особенно важных методов является аугментация данных - то есть, генерация дополнительных данных для тренировки на основе изначальных.   \n",
    "Таким образом, мы получаем возможность \"увеличить\" набор данных для тренировки, что ведет к лучшей работе сети.\n",
    "Важно, чтобы аугментированные данные были похожи на те, которые могут встретиться в реальной жизни, иначе польза от аугментаций уменьшается и может ухудшить работу сети.\n",
    "\n",
    "С PyTorch идут несколько таких алгоритмов, называемых `transforms`. Более подробно про них можно прочитать тут -\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#transforms\n",
    "\n",
    "Ниже мы используем следующие алгоритмы генерации:\n",
    "- ColorJitter - случайное изменение цвета\n",
    "- RandomHorizontalFlip - горизонтальное отражение с вероятностью 50%\n",
    "- RandomVerticalFlip - вертикальное отражение с вероятностью 50%\n",
    "- RandomRotation - случайный поворот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jCWMUWmr7t5g"
   },
   "outputs": [],
   "source": [
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.50, saturation=.50),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(50, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                       std=[0.20,0.20,0.20])                           \n",
    "])\n",
    "\n",
    "# Create augmented train dataset\n",
    "data_aug_train = dset.SVHN('data/', \n",
    "                       transform=tfs\n",
    "                      )\n",
    "\n",
    "train_aug_loader = torch.utils.data.DataLoader(data_aug_train, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_get_iterator',\n",
       " '_index_sampler',\n",
       " '_is_protocol',\n",
       " '_iterator',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'check_worker_number_rationality',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'generator',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'persistent_workers',\n",
       " 'pin_memory',\n",
       " 'pin_memory_device',\n",
       " 'prefetch_factor',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_aug_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результаты агментации (вообще, смотреть на сгенерированные данные всегда очень полезно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YlJJEro1KZ45"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3000x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Visualize some augmented images!\n",
    "# hint: you can create new datasets and loaders to accomplish this\n",
    "\n",
    "# Based on the visualizations, should we keep all the augmentations?\n",
    "\n",
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "   #transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30, interpolation=InterpolationMode.BILINEAR),\n",
    "])\n",
    "\n",
    "data_aug_vis = dset.SVHN('data/', \n",
    "                       transform=tfs\n",
    "                      )\n",
    "\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i, (x, y) in enumerate(data_aug_vis):\n",
    "    if i == 10:\n",
    "        break\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2LrmsYHoguB"
   },
   "source": [
    "Все ли агментации одинаково полезны на этом наборе данных? Могут ли быть среди них те, которые собьют модель с толку?\n",
    "\n",
    "Выберите из них только корректные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evro9ksXGs9u"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "    transforms.RandomRotation(30, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                       std=[0.20,0.20,0.20])                           \n",
    "])\n",
    "\n",
    "# TODO create new instances of loaders with the augmentations you chose\n",
    "train_aug_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "data_train = dset.SVHN('data/', \n",
    "                       download = True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                          \n",
    "                       ])\n",
    "                      )\n",
    "data_train_trans =  dset.SVHN('data/', \n",
    "                       download = True,\n",
    "                       transform=transforms.Compose([\n",
    "                            transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "                            transforms.RandomRotation(30, interpolation=InterpolationMode.BILINEAR),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])\n",
    "                       ])\n",
    "                    )\n",
    "\n",
    "data_test = dset.SVHN('data/', split='test', \n",
    "                      download = True,\n",
    "                      transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                           \n",
    "                       ]))\n",
    "batch_size = 64\n",
    "\n",
    "data_size = data_train.data.shape[0]\n",
    "validation_split = .2\n",
    "split = int(np.floor(validation_split * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for num in train_sampler:\n",
    "    X, y = data_train[num]\n",
    "    data_list.append((X, y))\n",
    "    X, y = data_train_trans[num]\n",
    "    data_list.append((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n",
    "                                         sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(4),    \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*2*2, 10),\n",
    "          )\n",
    "\n",
    "nn_model.type(torch.cuda.FloatTensor)\n",
    "nn_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(nn_model.parameters(), lr=1e-1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeO6Zw0DHqPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.295433, Train accuracy: 0.565556, Val accuracy: 0.727391\n",
      "Average loss: 0.768081, Train accuracy: 0.758941, Val accuracy: 0.806088\n",
      "Average loss: 0.683362, Train accuracy: 0.787667, Val accuracy: 0.795850\n",
      "Average loss: 0.638245, Train accuracy: 0.802136, Val accuracy: 0.827589\n",
      "Average loss: 0.607504, Train accuracy: 0.811794, Val accuracy: 0.829431\n",
      "Average loss: 0.586251, Train accuracy: 0.819464, Val accuracy: 0.818920\n",
      "Average loss: 0.568567, Train accuracy: 0.823875, Val accuracy: 0.825677\n",
      "Average loss: 0.555064, Train accuracy: 0.828823, Val accuracy: 0.847860\n",
      "Average loss: 0.541858, Train accuracy: 0.832875, Val accuracy: 0.843628\n",
      "Average loss: 0.535339, Train accuracy: 0.834386, Val accuracy: 0.837076\n"
     ]
    }
   ],
   "source": [
    "# Finally, let's train with augmentations!\n",
    "\n",
    "# Note we shouldn't use augmentations on validation\n",
    "\n",
    "loss_history, train_history, val_history = train_model(nn_model, train_loader, val_loader, loss, optimizer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0bcioK6JBDK"
   },
   "source": [
    "# LeNet\n",
    "Попробуем имплементировать классическую архитектуру сверточной нейронной сети, предложенную Яном ЛеКуном в 1998 году. В свое время она достигла впечатляющих результатов на MNIST, посмотрим как она справится с SVHN?\n",
    "Она описана в статье [\"Gradient Based Learning Applied to Document Recognition\"](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf), попробуйте прочитать ключевые части и имплементировать предложенную архитетуру на PyTorch.\n",
    "\n",
    "Реализовывать слои и функцию ошибки LeNet, которых нет в PyTorch, **не нужно** - просто возьмите их размеры и переведите в уже известные нам Convolutional, Pooling и Fully Connected layers.\n",
    "\n",
    "Если в статье не очень понятно, можно просто погуглить LeNet и разобраться в деталях :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieEzZUglJAUB"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement LeNet-like architecture for SVHN task\n",
    "lenet_model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, 10),\n",
    "          )\n",
    "\n",
    "lenet_model.type(torch.cuda.FloatTensor)\n",
    "lenet_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.SGD(lenet_model.parameters(), lr=1e-1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMmaPfdeKk9H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.555445, Train accuracy: 0.468092, Val accuracy: 0.789229\n",
      "Average loss: 0.614741, Train accuracy: 0.807955, Val accuracy: 0.845813\n",
      "Average loss: 0.506912, Train accuracy: 0.842141, Val accuracy: 0.864105\n",
      "Average loss: 0.452312, Train accuracy: 0.859426, Val accuracy: 0.881373\n",
      "Average loss: 0.414634, Train accuracy: 0.871174, Val accuracy: 0.882738\n",
      "Average loss: 0.385964, Train accuracy: 0.879517, Val accuracy: 0.883489\n",
      "Average loss: 0.363094, Train accuracy: 0.886582, Val accuracy: 0.883830\n",
      "Average loss: 0.345538, Train accuracy: 0.893006, Val accuracy: 0.881169\n",
      "Average loss: 0.329264, Train accuracy: 0.897826, Val accuracy: 0.891816\n",
      "Average loss: 0.314598, Train accuracy: 0.902365, Val accuracy: 0.888677\n"
     ]
    }
   ],
   "source": [
    "# Let's train it!\n",
    "loss_history, train_history, val_history = train_model(lenet_model, train_loader, val_loader, loss, optimizer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_O9qiYySvuj"
   },
   "source": [
    "optuna-dashboard sqlite:///db.sqlite3# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://optuna.readthedocs.io/en/stable/tutorial/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6mhfdQ9K-N3"
   },
   "outputs": [],
   "source": [
    "# The key hyperparameters we're going to tune are learning speed, annealing rate and regularization\n",
    "# We also encourage you to try different optimizers as well\n",
    "\n",
    "Hyperparams = namedtuple(\"Hyperparams\", ['learning_rate', 'anneal_epochs', 'reg'])\n",
    "RunResult = namedtuple(\"RunResult\", ['model', 'train_history', 'val_history', 'final_val_accuracy'])\n",
    "\n",
    "learning_rates = [1e0, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "anneal_coeff = 0.2\n",
    "anneal_epochs = [1, 5, 10, 15, 20, 50]\n",
    "reg = [1e-3, 1e-4, 1e-5, 1e-7]\n",
    "\n",
    "batch_size = 64\n",
    "epoch_num = 10\n",
    "\n",
    "# Record all the runs here\n",
    "# Key should be Hyperparams and values should be RunResult\n",
    "run_record = {} \n",
    "\n",
    "# Use grid search or random search and record all runs in run_record dictionnary \n",
    "# Important: perform search in logarithmic space!\n",
    "\n",
    "# TODO: Your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y6xExdw8JB1l",
    "outputId": "a9ad86f8-3e29-45cc-d33f-e6170018a4ed"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m         best_hyperparams \u001b[38;5;241m=\u001b[39m hyperparams\n\u001b[0;32m      9\u001b[0m         best_run \u001b[38;5;241m=\u001b[39m run_result\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBest validation accuracy: \u001b[39;49m\u001b[38;5;132;43;01m%4.2f\u001b[39;49;00m\u001b[38;5;124;43m, best hyperparams: \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_val_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_hyperparams\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "best_val_accuracy = None\n",
    "best_hyperparams = None\n",
    "best_run = None\n",
    "\n",
    "for hyperparams, run_result in run_record.items():\n",
    "    if best_val_accuracy is None or best_val_accuracy < run_result.final_val_accuracy:\n",
    "        best_val_accuracy = run_result.final_val_accuracy\n",
    "        best_hyperparams = hyperparams\n",
    "        best_run = run_result\n",
    "        \n",
    "print(\"Best validation accuracy: %4.2f, best hyperparams: %s\" % (best_val_accuracy, best_hyperparams))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ищем оптимальные гиперпараметры с optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/train_32x32.mat\n",
      "Using downloaded and verified file: data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "tfs = transforms.Compose([\n",
    "    transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "    transforms.RandomRotation(30, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                       std=[0.20,0.20,0.20])                           \n",
    "])\n",
    "\n",
    "data_train = dset.SVHN('data/', \n",
    "                       download = True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                          \n",
    "                       ])\n",
    "                      )\n",
    "data_train_trans =  dset.SVHN('data/', \n",
    "                       download = True,\n",
    "                       transform=transforms.Compose([\n",
    "                            transforms.ColorJitter(hue=.20, saturation=.20),\n",
    "                            transforms.RandomRotation(30, interpolation=InterpolationMode.BILINEAR),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])\n",
    "                       ])\n",
    "                    )\n",
    "\n",
    "data_test = dset.SVHN('data/', split='test', \n",
    "                      download = True,\n",
    "                      transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[0.43,0.44,0.47],\n",
    "                                               std=[0.20,0.20,0.20])                           \n",
    "                       ]))\n",
    "data_size = data_train.data.shape[0]\n",
    "validation_split = .2\n",
    "split = int(np.floor(validation_split * data_size))\n",
    "indices = list(range(data_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for num in train_sampler:\n",
    "    X, y = data_train[num]\n",
    "    data_list.append((X, y))\n",
    "    X, y = data_train_trans[num]\n",
    "    data_list.append((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):    \n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "          \n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "        val_accuracy = compute_accuracy(model, val_loader)\n",
    "        \n",
    "        loss_history.append(float(ave_loss))\n",
    "        train_history.append(train_accuracy)\n",
    "        val_history.append(val_accuracy)\n",
    "        \n",
    "        #print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    return loss_history, train_history, val_history\n",
    "        \n",
    "def compute_accuracy(model, loader):\n",
    "    val_size = 0\n",
    "    good_predict = 0\n",
    "    model.eval() # Evaluation mode\n",
    "    for i_step, (X, y) in enumerate(loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        prediction = model(X)\n",
    "        _, index = torch.max(prediction, 1)\n",
    "        good_predict += torch.sum(index == y)\n",
    "        val_size += X.shape[0]\n",
    "    \n",
    "    accuracy =  float(good_predict)/val_size\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    lenet_model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, 10),\n",
    "          )\n",
    "    return lenet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluet(param, model):\n",
    "    train_loader = torch.utils.data.DataLoader(data_list, batch_size=param['batch_size'], shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(data_train, batch_size=param['batch_size'],\n",
    "                                             sampler=val_sampler)\n",
    "    model.type(torch.cuda.FloatTensor)\n",
    "    model.to(device)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=param['lr'])\n",
    "    loss_history, train_history, val_history = train_model(model, train_loader, val_loader, loss, optimizer, param['epochs'])\n",
    "    return val_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "     params = {\n",
    "              'lr': trial.suggest_loguniform('learning_rate', 1e-5, 1e0),\n",
    "              'epochs': trial.suggest_int(\"epochs\", 20, 50),\n",
    "              'batch_size': trial.suggest_int(\"batch_size\", 32, 64)\n",
    "              }\n",
    "    \n",
    "     model = make_model()\n",
    "     accuracy = train_and_evaluet(params, model)\n",
    "\n",
    "     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-26 21:16:13,120]\u001b[0m A new study created in memory with name: no-name-47fa36b1-dfc2-4a60-9de4-e7f88e033d09\u001b[0m\n",
      "C:\\Users\\budni\\AppData\\Local\\Temp\\ipykernel_22952\\4180604203.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  'lr': trial.suggest_loguniform('learning_rate', 1e-5, 1e0),\n",
      "\u001b[32m[I 2023-01-26 21:24:00,192]\u001b[0m Trial 0 finished with value: 0.878028803494642 and parameters: {'learning_rate': 0.0034254678511851265, 'epochs': 43, 'batch_size': 56}. Best is trial 0 with value: 0.878028803494642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 21:27:41,121]\u001b[0m Trial 1 finished with value: 0.8169408231520032 and parameters: {'learning_rate': 0.002980030663693968, 'epochs': 22, 'batch_size': 62}. Best is trial 0 with value: 0.878028803494642.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 21:35:06,772]\u001b[0m Trial 2 finished with value: 0.8917480035492458 and parameters: {'learning_rate': 0.005865090315293377, 'epochs': 42, 'batch_size': 60}. Best is trial 2 with value: 0.8917480035492458.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 21:42:33,558]\u001b[0m Trial 3 finished with value: 0.8948194662480377 and parameters: {'learning_rate': 0.008188850334880572, 'epochs': 42, 'batch_size': 57}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 21:53:58,506]\u001b[0m Trial 4 finished with value: 0.19213705549109275 and parameters: {'learning_rate': 2.2738576120664035e-05, 'epochs': 47, 'batch_size': 38}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:02:02,943]\u001b[0m Trial 5 finished with value: 0.19213705549109275 and parameters: {'learning_rate': 5.180481508675694e-05, 'epochs': 31, 'batch_size': 38}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:09:12,876]\u001b[0m Trial 6 finished with value: 0.8423998361886561 and parameters: {'learning_rate': 0.5714342607711853, 'epochs': 39, 'batch_size': 60}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:15:40,841]\u001b[0m Trial 7 finished with value: 0.7141492048324346 and parameters: {'learning_rate': 0.0010209429393155936, 'epochs': 23, 'batch_size': 32}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:24:14,634]\u001b[0m Trial 8 finished with value: 0.8468363934202443 and parameters: {'learning_rate': 0.48776606211328666, 'epochs': 38, 'batch_size': 41}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:28:07,043]\u001b[0m Trial 9 finished with value: 0.1988260187017951 and parameters: {'learning_rate': 0.0006803371234568414, 'epochs': 23, 'batch_size': 62}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:37:37,386]\u001b[0m Trial 10 finished with value: 0.882943143812709 and parameters: {'learning_rate': 0.020719592174274007, 'epochs': 50, 'batch_size': 51}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:45:22,813]\u001b[0m Trial 11 finished with value: 0.8900416353832503 and parameters: {'learning_rate': 0.028437258762854606, 'epochs': 43, 'batch_size': 53}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:51:51,105]\u001b[0m Trial 12 finished with value: 0.8888813050303733 and parameters: {'learning_rate': 0.028638644106641655, 'epochs': 32, 'batch_size': 46}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 22:59:25,246]\u001b[0m Trial 13 finished with value: 0.8765954542352058 and parameters: {'learning_rate': 0.0830117815857017, 'epochs': 44, 'batch_size': 57}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:05:13,171]\u001b[0m Trial 14 finished with value: 0.19213705549109275 and parameters: {'learning_rate': 0.0001992320604448384, 'epochs': 37, 'batch_size': 64}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:11:39,282]\u001b[0m Trial 15 finished with value: 0.8942051737082793 and parameters: {'learning_rate': 0.0068606801515918095, 'epochs': 33, 'batch_size': 48}. Best is trial 3 with value: 0.8948194662480377.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:17:23,876]\u001b[0m Trial 16 finished with value: 0.8950924851545969 and parameters: {'learning_rate': 0.007860987008889287, 'epochs': 29, 'batch_size': 47}. Best is trial 16 with value: 0.8950924851545969.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:23:13,140]\u001b[0m Trial 17 finished with value: 0.23698041089345437 and parameters: {'learning_rate': 0.0006832211229189813, 'epochs': 28, 'batch_size': 44}. Best is trial 16 with value: 0.8950924851545969.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:28:23,038]\u001b[0m Trial 18 finished with value: 0.878028803494642 and parameters: {'learning_rate': 0.0921460938580582, 'epochs': 27, 'batch_size': 50}. Best is trial 16 with value: 0.8950924851545969.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:33:26,409]\u001b[0m Trial 19 finished with value: 0.19213705549109275 and parameters: {'learning_rate': 0.00018588414407594487, 'epochs': 28, 'batch_size': 54}. Best is trial 16 with value: 0.8950924851545969.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:40:49,710]\u001b[0m Trial 20 finished with value: 0.19131799877141492 and parameters: {'learning_rate': 1.0901173445473656e-05, 'epochs': 35, 'batch_size': 43}. Best is trial 16 with value: 0.8950924851545969.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:47:02,124]\u001b[0m Trial 21 finished with value: 0.9025322503583373 and parameters: {'learning_rate': 0.00995152678426102, 'epochs': 31, 'batch_size': 47}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:52:16,510]\u001b[0m Trial 22 finished with value: 0.8968671080472322 and parameters: {'learning_rate': 0.009712468526740195, 'epochs': 26, 'batch_size': 47}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-26 23:57:25,697]\u001b[0m Trial 23 finished with value: 0.846563374513685 and parameters: {'learning_rate': 0.002230556951931576, 'epochs': 26, 'batch_size': 47}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-27 00:01:59,605]\u001b[0m Trial 24 finished with value: 0.8952972493345164 and parameters: {'learning_rate': 0.015776265117822205, 'epochs': 20, 'batch_size': 40}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-27 00:06:52,972]\u001b[0m Trial 25 finished with value: 0.8921575319090848 and parameters: {'learning_rate': 0.01575740580430961, 'epochs': 20, 'batch_size': 38}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-27 00:13:24,719]\u001b[0m Trial 26 finished with value: 0.8815097945532728 and parameters: {'learning_rate': 0.05647621700050918, 'epochs': 25, 'batch_size': 34}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-27 00:18:08,945]\u001b[0m Trial 27 finished with value: 0.8768002184151252 and parameters: {'learning_rate': 0.12066803881638763, 'epochs': 20, 'batch_size': 41}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-27 00:24:55,545]\u001b[0m Trial 28 finished with value: 0.8982322025800287 and parameters: {'learning_rate': 0.01182177045625686, 'epochs': 30, 'batch_size': 44}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n",
      "\u001b[32m[I 2023-01-27 00:31:17,343]\u001b[0m Trial 29 finished with value: 0.8607603576547675 and parameters: {'learning_rate': 0.0022741416795835105, 'epochs': 30, 'batch_size': 44}. Best is trial 21 with value: 0.9025322503583373.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LOmsR0uVgtgf",
    "tags": []
   },
   "source": [
    "# Свободное упражнение - догоним и перегоним LeNet!\n",
    "\n",
    "Попробуйте найти архитектуру и настройки тренировки, чтобы выступить лучше наших бейзлайнов.\n",
    "\n",
    "Что можно и нужно попробовать:\n",
    "- BatchNormalization (для convolution layers он в PyTorch называется [batchnorm2d](https://pytorch.org/docs/stable/nn.html#batchnorm2d))\n",
    "- Изменить количество слоев и их толщину\n",
    "- Изменять количество эпох тренировки\n",
    "- Попробовать и другие агментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tSVhD747icoc"
   },
   "outputs": [],
   "source": [
    "best_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubeKgBcnhx7N"
   },
   "source": [
    "# Финальный аккорд - проверим лучшую модель на test set\n",
    "\n",
    "В качестве разнообразия - напишите код для прогона модели на test set вы.\n",
    "\n",
    "В результате вы должны натренировать модель, которая покажет более **90%** точности на test set.  \n",
    "Как водится, лучший результат в группе получит дополнительные баллы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIqM1kdeh-hd"
   },
   "outputs": [],
   "source": [
    "# TODO Write the code to compute accuracy on test set\n",
    "final_test_accuracy = 0.0\n",
    "print(\"Final test accuracy - \", final_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BfH6qip6kVX_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch_CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
